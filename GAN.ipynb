{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appersaravanan/AI_Assignment3/blob/master/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "368N7QLmoRDF"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import UpSampling2D,Input,BatchNormalization,Conv2D,Activation,Dropout,LeakyReLU,Flatten,Dense,Conv2DTranspose,Reshape\n",
        "\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.data import Dataset\n",
        "import time,os\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SPdv_KFK8AD"
      },
      "source": [
        "##Load data from mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ8PptxFU-RX"
      },
      "source": [
        "                                                                    \n",
        "\n",
        "## Input is defined based on the mnist deminsion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pcSUoq8TNrX"
      },
      "source": [
        "#input shape. cifar images are 32*32 and with RGB color as 3\n",
        "input_shape=(28,28,1)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_y52HDaT7eN"
      },
      "source": [
        "#Encoder part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVxQrNKTWyjY"
      },
      "source": [
        "\n",
        "\n",
        "def def_discriminator():\n",
        "  x = Sequential();\n",
        "  x.add(Conv2D(filters=32, kernel_size=(5, 5),  strides=(2,2) ,padding='same',input_shape=input_shape))\n",
        "  x.add(LeakyReLU(0.2))\n",
        "  x.add(Dropout(0.4))\n",
        "\n",
        "  x.add(Conv2D(filters=64, kernel_size=(5, 5),  strides=(2,2), padding='same'))\n",
        "  x.add(LeakyReLU(0.2))\n",
        "  x.add(Dropout(0.4))\n",
        "\n",
        "  x.add(Conv2D(filters=128, kernel_size=(5, 5),  strides=(2,2), padding='same'))\n",
        "  x.add(LeakyReLU(0.2))\n",
        "  x.add(Dropout(0.4))\n",
        "\n",
        "  x.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(2,2), padding='same'))\n",
        "  x.add(LeakyReLU(0.2))\n",
        "  x.add(Dropout(0.4))\n",
        "  x.add(Flatten())\n",
        "  x.add(Dense(1,activation='sigmoid'))\n",
        "  img= Input(shape=input_shape)\n",
        "  validity=x(img)\n",
        "  return Model(img,validity)\n",
        "  \n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_pred = tf.sigmoid(real_output)\n",
        "    fake_pred = tf.sigmoid(fake_output)\n",
        "    real_loss = tf.losses.binary_crossentropy(tf.ones_like(real_pred), real_pred)\n",
        "    fake_loss = tf.losses.binary_crossentropy(tf.zeros_like(fake_pred), fake_pred)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "#discriminator.summary()\n",
        "# discriminator.compile (loss='binary_crossentropy',optimizer=Adam(1e-3), metrics=['accuracy'] )\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCaw62uJbrIY"
      },
      "source": [
        "dim=7\n",
        "depth=192\n",
        "\n",
        "def def_generator = Sequential()\n",
        "\n",
        "  g.add( Dense(dim*dim*depth,input_shape=(100,) )) \n",
        "  g.add( BatchNormalization())\n",
        "  g.add( Activation('relu'))\n",
        "\n",
        "  g.add( Reshape((dim, dim, depth)))\n",
        "  g.add( Dropout(0.4))\n",
        "  g.add(UpSampling2D((2, 2)))\n",
        "\n",
        "  g.add( Conv2DTranspose(filters=96, kernel_size=(5, 5), strides=1, padding='same') )\n",
        "  g.add(BatchNormalization())\n",
        "  g.add( Activation('relu'))\n",
        "  g.add( UpSampling2D((2, 2)))\n",
        "\n",
        "  g.add( Conv2DTranspose(filters=48, kernel_size=(5, 5), strides=1, padding='same'))\n",
        "  g.add(BatchNormalization())\n",
        "\n",
        "  g.add( Activation('relu'))\n",
        "\n",
        "\n",
        "  g.add(Conv2DTranspose(filters=24, kernel_size=(5, 5), strides=1, padding='same'))\n",
        "  g.add( BatchNormalization())\n",
        "  g.add( Activation('relu'))\n",
        "\n",
        "\n",
        "  g.add( Conv2DTranspose(filters=1, kernel_size=(5, 5), strides=1, padding='same')) \n",
        "  g.add(Activation('sigmoid'))\n",
        "  #generator.compile (loss='binary_crossentropy',optimizer=RMSprop(lr=0.0001, decay=3e-8), metrics=['accuracy'] )\n",
        "\n",
        "  g.summary()\n",
        "  noise=Input(shape=(100,))\n",
        "  img =g(noise)\n",
        "\n",
        "  return Model(noise,img);\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJGlkGmBgX5r"
      },
      "source": [
        "batch_size=32\n",
        "(x_train, _), (_, _) = mnist.load_data()\n",
        " \n",
        "x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
        "x_train = np.expand_dims(x_train, axis=3) \n",
        "\n",
        "half_batch = int(batch_size / 2)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMHl2yj3-sJR",
        "outputId": "6ec05b5d-6cfd-48fa-cd26-c45e3eb48bb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "def train(epochs, batch_size=128, save_interval=50):\n",
        " \n",
        "    for epoch in range(epochs):\n",
        "\n",
        "\n",
        "\n",
        "        idx = np.random.randint(0, x_train.shape[0], half_batch)\n",
        "        imgs = x_train[idx]\n",
        "\n",
        " \n",
        "        noise = np.random.normal(0, 1, (half_batch, 100))\n",
        "\n",
        "        gen_imgs = generator.predict(noise)\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
        "        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
        "    \n",
        "    \n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) \n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, 100)) \n",
        "\n",
        "        valid_y = np.array([1] * batch_size) #Creates an array of all ones of size=batch size\n",
        "\n",
        "        g_loss = combined.train_on_batch(noise, valid_y)\n",
        "\n",
        "       \n",
        "\n",
        "        # If at save interval => save generated image samples\n",
        "        if epoch % save_interval == 0 or epoch == save_interval :\n",
        "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "            save_imgs(epoch)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "def save_imgs(epoch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, 100))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    print( os.getcwd() )\n",
        "    fig.savefig(\"mnist_%d.png\" % epoch)\n",
        "    plt.close()\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6Ela7vRbdGe",
        "outputId": "0831e23e-3ce9-48c3-aa8a-c74cf3ab3098",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "discriminator = def_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "\n",
        "generator = def_generator()\n",
        "generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "z = Input(shape=(100,))  \n",
        "img = generator(z)\n",
        "\n",
        "discriminator.trainable = False  \n",
        "\n",
        "valid = discriminator(img)  #Validity check on the generated image\n",
        "\n",
        "\n",
        "\n",
        "combined = Model(z, valid)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "\n",
        "train(epochs=5000, batch_size=32, save_interval=500)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_15 (Dense)             (None, 9408)              950208    \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 9408)              37632     \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 9408)              0         \n",
            "_________________________________________________________________\n",
            "reshape_7 (Reshape)          (None, 7, 7, 192)         0         \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 7, 7, 192)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_14 (UpSampling (None, 14, 14, 192)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_28 (Conv2DT (None, 14, 14, 96)        460896    \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 14, 14, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_36 (Activation)   (None, 14, 14, 96)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_15 (UpSampling (None, 28, 28, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_29 (Conv2DT (None, 28, 28, 48)        115248    \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 28, 28, 48)        192       \n",
            "_________________________________________________________________\n",
            "activation_37 (Activation)   (None, 28, 28, 48)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_30 (Conv2DT (None, 28, 28, 24)        28824     \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 28, 28, 24)        96        \n",
            "_________________________________________________________________\n",
            "activation_38 (Activation)   (None, 28, 28, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_31 (Conv2DT (None, 28, 28, 1)         601       \n",
            "_________________________________________________________________\n",
            "activation_39 (Activation)   (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 1,594,081\n",
            "Trainable params: 1,574,929\n",
            "Non-trainable params: 19,152\n",
            "_________________________________________________________________\n",
            "0 [D loss: 0.754427, acc.: 31.25%] [G loss: 0.903526]\n",
            "/content\n",
            "500 [D loss: 0.758842, acc.: 43.75%] [G loss: 0.675251]\n",
            "/content\n",
            "1000 [D loss: 0.698157, acc.: 53.12%] [G loss: 0.736245]\n",
            "/content\n",
            "1500 [D loss: 0.671802, acc.: 59.38%] [G loss: 0.791079]\n",
            "/content\n",
            "2000 [D loss: 0.638286, acc.: 68.75%] [G loss: 0.760162]\n",
            "/content\n",
            "2500 [D loss: 0.648777, acc.: 62.50%] [G loss: 0.815670]\n",
            "/content\n",
            "3000 [D loss: 0.683363, acc.: 56.25%] [G loss: 0.882522]\n",
            "/content\n",
            "3500 [D loss: 0.671626, acc.: 56.25%] [G loss: 0.843470]\n",
            "/content\n",
            "4000 [D loss: 0.763450, acc.: 50.00%] [G loss: 0.885418]\n",
            "/content\n",
            "4500 [D loss: 0.664420, acc.: 56.25%] [G loss: 0.812552]\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxCh0eE1dr0u",
        "outputId": "9ab61d89-9c13-4769-956a-624ce35bb0e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print( os.listdir() )\n",
        "from google.colab import files\n",
        "files.download( \"mnist_4500.png\" ) "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.config', 'mnist_2500.png', 'mnist_4000.png', 'mnist_90.png', 'mnist_300.png', 'mnist_3000.png', 'mnist_3500.png', 'mnist_70.png', 'mnist_100.png', 'mnist_400.png', 'mnist_500.png', 'mnist_200.png', 'mnist_60.png', 'mnist_4500.png', 'mnist_80.png', 'mnist_1500.png', 'mnist_900.png', 'mnist_2000.png', 'mnist_30.png', 'mnist_0.png', 'mnist_600.png', 'mnist_1000.png', 'mnist_50.png', 'mnist_700.png', 'mnist_20.png', 'mnist_800.png', 'mnist_40.png', 'gdrive', 'mnist_10.png', 'sample_data']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7a24dbef-3b60-4d56-85e5-8d5d0d284c08\", \"mnist_4500.png\", 37472)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvfrqBaQG9PB"
      },
      "source": [
        "\n",
        "def train_step(images):\n",
        "    noise = np.random.randn(100, 100).astype(\"float32\")\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "      #print(generated_images)\n",
        "      real_output = dis_model(images, training=True)\n",
        "      #print(real_output)\n",
        "      fake_output = dis_model(generated_images, training=True)\n",
        "      #print(fake_output)\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      # print(gen_loss)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, dis_model.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, dis_model.trainable_variables))\n",
        "    #print(gen_loss)\n",
        "    print(\"gen loss: \", np.mean(gen_loss))\n",
        "    print(\"dis loss: \" ,np.mean(disc_loss))\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_4-6u-fA9Xk"
      },
      "source": [
        "def train(ds,epochs):\n",
        "  for i in range(epochs):\n",
        "    for images in ds:\n",
        "      # images= tf.cast(images,tf.dtypes.float32)\n",
        "      train_step(images)\n",
        "train(x_train_ds,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAR_VF7XP6rM",
        "outputId": "9e013275-8a7a-4c11-ad55-8c802e87d700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.imshow(tf.reshape(generator(np.random.randn(1,100)),(28,28)),cmap=\"gray\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f263e7e80b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPFklEQVR4nO3dW4xVdZbH8d8SRASV4BArFVS6p+XBYgz2BInJEIKS7qAv6otC4oRxzNAPjaFjP4xxHiROTMzES4wPRNoLYHrsdLxEY3SmEdsRY2wtCCMIduOgqKQA5RIUQriteaiNqcbaa5fnuov1/SSVqtrr/M9ZHPhx9jn/vfff3F0Azn7ndLsBAJ1B2IEkCDuQBGEHkiDsQBJjO/lgZsZH/0CbubsNt72pV3YzW2BmfzazT8zsnmbuC0B7WaPz7GY2RtJfJP1M0peSPpC0yN23BmN4ZQfarB2v7LMlfeLuO9z9mKTfSbqpifsD0EbNhH2qpC+G/P5lse2vmNkSM+s3s/4mHgtAk9r+AZ27r5S0UmI3HuimZl7Zd0m6bMjvlxbbANRQM2H/QNJ0M/uxmY2TtFDSK61pC0CrNbwb7+4nzGyppP+WNEbS0+7+Ucs6A9BSDU+9NfRgvGcH2q4tB9UAGD0IO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiio0s2Z2U27MU+vzNjxoywPn/+/LC+YsWK0tqxY8fCsciDV3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSGJUreJ6zjnl/zdNmjQpHFs1l71x48awfurUqdLazJkzw7FPPvlkWL/yyivD+pgxY8J69He4b9++cOz06dPD+sGDB8M66qdsFdemDqoxs88kfSPppKQT7j6rmfsD0D6tOILuOnf/ugX3A6CNeM8OJNFs2F3SH8xsg5ktGe4GZrbEzPrNrL/JxwLQhGZ34+e4+y4zu0TSWjP72N3fHnoDd18paaXU/Ad0ABrX1Cu7u+8qvu+V9JKk2a1oCkDrNRx2M5toZhee/lnSzyVtaVVjAFqrmd34HkkvFedqj5X0n+7+Xy3pqkQ013348OFw7MDAQFg/ceJEWL/gggtKa1dccUU4tqq3nTt3hvXozy1JU6dOLa1NmTIlHHvgwIGwvn79+rA+d+7csI76aDjs7r5DUnw0CYDaYOoNSIKwA0kQdiAJwg4kQdiBJM6aU1yjqTFJuvTSS8P6p59+Gtavv/760tpjjz0Wjr388svD+o4dO8L6woULw3o0bfjGG2+EY3t6esJ6lW+//Tas9/b2NjwWjSk7xZVXdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IYlQt2Ryd6lk1Z1s1l33y5MmwHs0XV50mevz48bAezeFL1afnRqLTXyXptddeC+tVvU2cODGsv//++6W1a6+9Nhx76NChsI4fhld2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUjirDmffcKECeHYsWPjQwqq5un7+vpKa1999VU4dvfu3WG9k38HZxo/fnxYX7p0aVi/7777wvr+/ftLa7fddls49r333gvrGB7nswPJEXYgCcIOJEHYgSQIO5AEYQeSIOxAEqPqfPZoPvro0aPh2Krz1avmujdv3tzw2Dqr6v3ZZ58N6+eee25Yj64jED2naL3KV3Yze9rM9prZliHbLjaztWa2vfg+ub1tAmjWSHbjV0lacMa2eyStc/fpktYVvwOoscqwu/vbks485vEmSauLn1dLurnFfQFosUbfs/e4++kLo+2WVLpgmJktkbSkwccB0CJNf0Dn7h6d4OLuKyWtlJo/EQZA4xqdettjZr2SVHzf27qWALRDo2F/RdLi4ufFkl5uTTsA2qVyN97MnpM0T9IUM/tS0n2SHpT0ezO7U9JOSbe2s8nTojnhaI3ydj92t40bN660Nn/+/HDs7bffHtaja/VL0ueffx7W33zzzdLa4cOHw7Forcqwu/uiklL8rwhArXC4LJAEYQeSIOxAEoQdSIKwA0mMqktJj1YXXnhhWJ8zZ05Yf+ihh8L69OnTS2tVp6C2W3Rq8f333x+OrapjeFxKGkiOsANJEHYgCcIOJEHYgSQIO5AEYQeSYJ69A2655Zaw/vzzz4f1aKnqs9ndd98d1h999NEOdTK6MM8OJEfYgSQIO5AEYQeSIOxAEoQdSIKwA0kwz94B06ZNC+vbtm0L6+PHjw/r0WW0qy6xfeTIkbC+YcOGsP7MM8+E9UceeaS01tvbG46tMmPGjLC+devWpu5/tGKeHUiOsANJEHYgCcIOJEHYgSQIO5AEYQeSYJ69A8yGnfb8zrx588J6X19fWH/nnXdKawcPHgzHVi2bvH///rBetaRz5PXXXw/rCxYsaPi+pfg6AHVegrtZDc+zm9nTZrbXzLYM2bbczHaZ2abi68ZWNgug9UayG79K0nD/xT7q7lcXX6+1ti0ArVYZdnd/W1K8Lweg9pr5gG6pmX1Y7OZPLruRmS0xs34z62/isQA0qdGwr5D0E0lXSxqQ9HDZDd19pbvPcvdZDT4WgBZoKOzuvsfdT7r7KUm/kTS7tW0BaLWGwm5mQ89NvEXSlrLbAqiHynl2M3tO0jxJUyTtkXRf8fvVklzSZ5J+4e4DlQ+WdJ69SrPXhY/+DkfzfPLx48fD+tixY8N6f3/5x0TXXHNNQz2NBmXz7PGzNThw0TCbn2q6IwAdxeGyQBKEHUiCsANJEHYgCcIOJMEprqitxx9/PKwvXbo0rB87dqy0NmnSpHDs0aNHw3qdcSlpIDnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCeXbU1g033BDWX3311bAeXeb6qquuCsd+/PHHYb3OmGcHkiPsQBKEHUiCsANJEHYgCcIOJEHYgSQqry4LdMt1110X1quOETl58mRp7aKLLmqop9GMV3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSCLNPLvZsKf4fqdqzjZaVrlq6eATJ06E9ei867PZhAkTwvqcOXOauv8jR46U1vbu3dvUfY9Gla/sZnaZmf3RzLaa2UdmtqzYfrGZrTWz7cX3ye1vF0CjRrIbf0LSr929T9K1kn5pZn2S7pG0zt2nS1pX/A6gpirD7u4D7r6x+PkbSdskTZV0k6TVxc1WS7q5XU0CaN4Pes9uZj+S9FNJf5LU4+4DRWm3pJ6SMUskLWm8RQCtMOJP483sAkkvSPqVux8aWvPBT7eG/YTL3Ve6+yx3n9VUpwCaMqKwm9m5Ggz6b939xWLzHjPrLeq9kvJ9vAmMIpW78TY4Z/WUpG3u/siQ0iuSFkt6sPj+cls6rImJEyeW1h5++OFwbNVli996662w/sQTT4T1Q4cOldYOHDgQjm33pcTHjBlTWrvrrrvCsX19fWE9WpJZktatW1daGxgYKK2drUbynv0fJP2jpM1mtqnYdq8GQ/57M7tT0k5Jt7anRQCtUBl2d39HUtkRKfNb2w6AduFwWSAJwg4kQdiBJAg7kARhB5JgyeYRik5jrVo6eP78eNIiOn1Wii+JLEm7d+8urS1evDgcu3379rAezeFL0iWXXBLW16xZU1qbNSs+qLLqz71169awvmzZstLau+++G44dzacds2QzkBxhB5Ig7EAShB1IgrADSRB2IAnCDiTBPHsLzJw5M6yvWrUqrE+bNi2sV11yOfo7jC6nPJL7rjoGoOoy2tElvKvmsjdt2hTWH3jggbC+fv360tq+ffvCsZ3MxQ8VPafuzjw7kB1hB5Ig7EAShB1IgrADSRB2IAnCDiTBPPsoMG7cuLB+xx13lNaWL18eju3pGXbVru9ULXVdJfr39cUXX4Rj586dG9Z37doV1qN5/NF8vnoV5tmB5Ag7kARhB5Ig7EAShB1IgrADSRB2IInKeXYzu0zSGkk9klzSSnd/zMyWS/oXSV8VN73X3V+ruC/m2WsmWj9dks4///ywft5554X16Hz6o0ePhmPrfE55nZXNs49kffYTkn7t7hvN7EJJG8xsbVF71N0falWTANpnJOuzD0gaKH7+xsy2SZra7sYAtNYPes9uZj+S9FNJfyo2LTWzD83saTObXDJmiZn1m1l/U50CaMqIj403swsk/Y+kB9z9RTPrkfS1Bt/H/7ukXnf/54r74E1YzfCe/ezT1LHxZnaupBck/dbdXyzucI+7n3T3U5J+I2l2q5oF0HqVYbfB056ekrTN3R8Zsr13yM1ukbSl9e0BaJWRTL3NkbRe0mZJp88LvFfSIklXa3A3/jNJvyg+zIvui/0yoM3KduM5nx04y3A+O5AcYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IImRXF22lb6WtHPI71OKbXVU197q2pdEb41qZW/TygodPZ/9ew9u1u/us7rWQKCuvdW1L4neGtWp3tiNB5Ig7EAS3Q77yi4/fqSuvdW1L4neGtWR3rr6nh1A53T7lR1AhxB2IImuhN3MFpjZn83sEzO7pxs9lDGzz8xss5lt6vb6dMUaenvNbMuQbReb2Voz2158H3aNvS71ttzMdhXP3SYzu7FLvV1mZn80s61m9pGZLSu2d/W5C/rqyPPW8ffsZjZG0l8k/UzSl5I+kLTI3bd2tJESZvaZpFnu3vUDMMxsrqRvJa1x978rtv2HpP3u/mDxH+Vkd//XmvS2XNK33V7Gu1itqHfoMuOSbpb0T+ricxf0das68Lx145V9tqRP3H2Hux+T9DtJN3Whj9pz97cl7T9j802SVhc/r9bgP5aOK+mtFtx9wN03Fj9/I+n0MuNdfe6CvjqiG2GfKumLIb9/qXqt9+6S/mBmG8xsSbebGUbPkGW2dkvq6WYzw6hcxruTzlhmvDbPXSPLnzeLD+i+b467/72kGyT9sthdrSUffA9Wp7nTFZJ+osE1AAckPdzNZoplxl+Q9Ct3PzS01s3nbpi+OvK8dSPsuyRdNuT3S4ttteDuu4rveyW9pPotRb3n9Aq6xfe9Xe7nO3Vaxnu4ZcZVg+eum8ufdyPsH0iabmY/NrNxkhZKeqULfXyPmU0sPjiRmU2U9HPVbynqVyQtLn5eLOnlLvbyV+qyjHfZMuPq8nPX9eXP3b3jX5Ju1OAn8v8n6d+60UNJX38r6X+Lr4+63Zuk5zS4W3dcg59t3CnpbyStk7Rd0huSLq5Rb89qcGnvDzUYrN4u9TZHg7voH0raVHzd2O3nLuirI88bh8sCSfABHZAEYQeSIOxAEoQdSIKwA0kQdiAJwg4k8f9T0DTsinSoTgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}