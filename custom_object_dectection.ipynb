{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_object dectection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "history_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appersaravanan/Semeter-2-Assignment-1/blob/master/custom_object_dectection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B71u175sCE2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96907c3a-3df0-4055-e6d9-8eeee787d527"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "# !wget https://ai.stanford.edu/~jkrause/cars/car_devkit.tgz\n",
        "# !wget http://imagenet.stanford.edu/internal/car196/cars_train.tgz\n",
        "# (train_ds, val_ds, test_ds), metadata = tfds.load(\n",
        "#     'cars196',\n",
        "#     split=['train[:80%]'],\n",
        "#     with_info=True\n",
        "# )\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# https://github.com/deanwetherby/tf_oda_stanford_cars\n",
        "\n",
        "# https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9\n",
        "# https://github.com/Tony607/object_detection_demo\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4l6GLrsp7Hd"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import densenet\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.applications import VGG16\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import  MaxPooling2D,UpSampling2D,Input,BatchNormalization,Conv2D,Activation,MaxPool2D,Flatten,Dense,GlobalAveragePooling2D,Lambda,Concatenate,GlobalMaxPooling2D,Add,multiply\n",
        "from tensorflow.keras.models import Model,Sequential,load_model\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import image as image_utils\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.applications import VGG16\n",
        "import cv2,os,tempfile\n",
        "import requests\n",
        "from keras.preprocessing import image\n",
        "from scipy.io import loadmat\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.layers import  Reshape\n",
        "import hashlib\n",
        "import io\n",
        "import logging\n",
        "import csv\n",
        "import PIL.Image\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME4o5kyqqEec"
      },
      "source": [
        "img_width, img_height = 224, 224\n",
        "nb_train_samples = 8144\n",
        "nb_validation_samples = 4899\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        "n_classes = 196\n",
        "path_base='/content/drive/MyDrive/semester_2_final_project/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnSVS02BqOb0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cp /content/drive/MyDrive/YOLOv4_weight/data/cars_train.tgz /content/drive/MyDrive/semester_2_final_project/data/training_set/\n",
        "%cd /content/drive/MyDrive/semester_2_final_project/data/training_set/\n",
        "!tar xvzf cars_train.tgz\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmAnqaZNBftk"
      },
      "source": [
        "%cp /content/drive/MyDrive/semester_2_final_project/cars_test.zip /content/drive/MyDrive/semester_2_final_project/data/test_set/\n",
        "%cd /content/drive/MyDrive/semester_2_final_project/data/test_set/\n",
        "!sudo unzip cars_test.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C16oTBqdHwhL",
        "outputId": "7f9ef561-40b2-4d9a-d405-8c59b69e4553"
      },
      "source": [
        "%cd /content/drive/MyDrive/semester_2_final_project/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/semester_2_final_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAO2wbigrUfy",
        "outputId": "225cfdde-509e-4ace-a2a9-3b4689ddfb49"
      },
      "source": [
        "\n",
        "\n",
        "!rm -f car_devkit.tgz\n",
        "!wget https://ai.stanford.edu/~jkrause/cars/car_devkit.tgz\n",
        "!tar xvzf car_devkit.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-29 16:40:50--  https://ai.stanford.edu/~jkrause/cars/car_devkit.tgz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 330960 (323K) [application/x-gzip]\n",
            "Saving to: ‘car_devkit.tgz’\n",
            "\n",
            "car_devkit.tgz      100%[===================>] 323.20K  1.53MB/s    in 0.2s    \n",
            "\n",
            "2021-04-29 16:40:51 (1.53 MB/s) - ‘car_devkit.tgz’ saved [330960/330960]\n",
            "\n",
            "devkit/\n",
            "devkit/cars_meta.mat\n",
            "devkit/cars_train_annos.mat\n",
            "devkit/cars_test_annos.mat\n",
            "devkit/README.txt\n",
            "devkit/train_perfect_preds.txt\n",
            "devkit/eval_train.m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9rC6jt5tTGr"
      },
      "source": [
        "# !wget http://imagenet.stanford.edu/internal/car196/cars_train.tgz\n",
        "\n",
        "# !tar xvzf cars_train.tgz\n",
        "# !rm -f cars_train.tgz\n",
        "# !wget http://imagenet.stanford.edu/internal/car196/cars_test.tgz\n",
        "# !tar xvzf cars_test.tgz\n",
        "# !rm -f cars_test.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v6l7PWYL7kI"
      },
      "source": [
        "%cd {path_base}'data/inputs'\n",
        "assert os.getcwd()=='/content/drive/MyDrive/semester_2_final_project/data/inputs', 'Directory should be \"/content/drive/MyDrive/semester_2_final_project/data/inputs\" instead of \"{}\"'.format(os.getcwd())\n",
        "!rm -Rfv ./*\n",
        "!pwd\n",
        "annotsa = loadmat('/content/drive/MyDrive/semester_2_final_project/devkit/cars_meta.mat')\n",
        "i=1\n",
        "classes_name=[]\n",
        "labelMap='';\n",
        "for name in annotsa['class_names'][0]:\n",
        "  dir_name=str(i)+'_'+str(name[0]).replace(' ','_')\n",
        "  os.makedirs(dir_name)\n",
        "  if i<10:\n",
        "    classes_name.append(dir_name)  \n",
        "    labelMap+=' item { \\n \\t id:'+ str(i) +' \\n \\t name:' +\" '\" + dir_name +\"' \\n } \\n \\n\"\n",
        "  i=i+1\n",
        "labelMap\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3U3WfNRZw7G"
      },
      "source": [
        "f= open(\"/content/drive/MyDrive/semester_2_final_project/data/annotations/train_label_map_10.pbtxt\",\"w+\")\n",
        "f.write(labelMap)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpvFfBHNUyvr"
      },
      "source": [
        "import shutil\n",
        "from shutil import copyfile\n",
        "\n",
        "from_train_data_dir = '/content/drive/MyDrive/semester_2_final_project/data/training_set/cars_train'\n",
        "to_directory ='/content/drive/MyDrive/semester_2_final_project/data/inputs'\n",
        "\n",
        "annos = loadmat('/content/drive/MyDrive/semester_2_final_project/devkit/cars_train_annos.mat')\n",
        "data = [[row.flat[0] for row in line] for line in annos['annotations'][0]]\n",
        "columns = ['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2', 'class', 'fname']\n",
        "df_train = pd.DataFrame(data, columns=columns)\n",
        "gp=df_train.groupby('class')\n",
        "files=\"\"\n",
        "# for index,classes in gp:\n",
        "    \n",
        "#     files=classes['fname']\n",
        "#     i=0\n",
        "#     for name,file in files.items():\n",
        "#         print(file)\n",
        "#         copyfile('{}/{}'.format(from_train_data_dir,file),'{}/{}/{}'.format(to_directory,classes_name[index-1],file))\n",
        "        \n",
        "#         i=i+1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjdmzUOXqOtn"
      },
      "source": [
        "trimmed_data_set= df_train.loc[df_train['class']<10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S0miAiytzO4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "917faa58-a838-474f-8706-19780977d136"
      },
      "source": [
        "trimmed_data_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>bbox_x1</th>\n",
              "      <th>bbox_y1</th>\n",
              "      <th>bbox_x2</th>\n",
              "      <th>bbox_y2</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00002.jpg</td>\n",
              "      <td>36</td>\n",
              "      <td>116</td>\n",
              "      <td>868</td>\n",
              "      <td>587</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>00065.jpg</td>\n",
              "      <td>63</td>\n",
              "      <td>175</td>\n",
              "      <td>417</td>\n",
              "      <td>320</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>00069.jpg</td>\n",
              "      <td>142</td>\n",
              "      <td>124</td>\n",
              "      <td>675</td>\n",
              "      <td>445</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>00081.jpg</td>\n",
              "      <td>10</td>\n",
              "      <td>55</td>\n",
              "      <td>540</td>\n",
              "      <td>271</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>00150.jpg</td>\n",
              "      <td>11</td>\n",
              "      <td>208</td>\n",
              "      <td>596</td>\n",
              "      <td>386</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8017</th>\n",
              "      <td>08018.jpg</td>\n",
              "      <td>181</td>\n",
              "      <td>51</td>\n",
              "      <td>427</td>\n",
              "      <td>232</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8030</th>\n",
              "      <td>08031.jpg</td>\n",
              "      <td>12</td>\n",
              "      <td>16</td>\n",
              "      <td>117</td>\n",
              "      <td>71</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8095</th>\n",
              "      <td>08096.jpg</td>\n",
              "      <td>25</td>\n",
              "      <td>118</td>\n",
              "      <td>319</td>\n",
              "      <td>232</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8126</th>\n",
              "      <td>08127.jpg</td>\n",
              "      <td>38</td>\n",
              "      <td>29</td>\n",
              "      <td>380</td>\n",
              "      <td>177</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8132</th>\n",
              "      <td>08133.jpg</td>\n",
              "      <td>57</td>\n",
              "      <td>236</td>\n",
              "      <td>881</td>\n",
              "      <td>569</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>373 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          fname  bbox_x1  bbox_y1  bbox_x2  bbox_y2  class\n",
              "1     00002.jpg       36      116      868      587      3\n",
              "64    00065.jpg       63      175      417      320      8\n",
              "68    00069.jpg      142      124      675      445      5\n",
              "80    00081.jpg       10       55      540      271      8\n",
              "149   00150.jpg       11      208      596      386      8\n",
              "...         ...      ...      ...      ...      ...    ...\n",
              "8017  08018.jpg      181       51      427      232      6\n",
              "8030  08031.jpg       12       16      117       71      1\n",
              "8095  08096.jpg       25      118      319      232      8\n",
              "8126  08127.jpg       38       29      380      177      5\n",
              "8132  08133.jpg       57      236      881      569      3\n",
              "\n",
              "[373 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvkDpk6ZX0DL"
      },
      "source": [
        "print(trimmed_data_set.columns.to_list())\n",
        "\n",
        "columns = ['fname','bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2', 'class']\n",
        "trimmed_data_set=trimmed_data_set[columns]\n",
        "print(trimmed_data_set.columns.to_list())\n",
        "print(trimmed_data_set.to_csv())\n",
        "f= open(\"/content/drive/MyDrive/semester_2_final_project/data/annotations/train.csv\",\"w+\")\n",
        "f.write(trimmed_data_set.to_csv())\n",
        "f.close()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY8zOKPMulZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6df63bb3-a4bd-4a5b-84d1-6bc885406d23"
      },
      "source": [
        "%cd /content/drive/MyDrive/semester_2_final_project/tf_model\n",
        "\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "!pip install tf_slim\n",
        "\n",
        "%cd /content/drive/MyDrive/semester_2_final_project/tf_model/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/drive/MyDrive/semester_2_final_project/tf_model/models:/content/drive/MyDrive/semester_2_final_project/tf_model/models/research/:/content/drive/MyDrive/semester_2_final_project/tf_model/models/research/slim/'\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/semester_2_final_project/tf_model/models\")\n",
        "\n",
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/semester_2_final_project/tf_model\n",
            "fatal: destination path 'models' already exists and is not an empty directory.\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 160690 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.4_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.4) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.5_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.5) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.4) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.5) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n",
            "/content/drive/MyDrive/semester_2_final_project/tf_model/models/research\n",
            "2021-05-02 15:34:02.100824: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Running tests under Python 3.7.10: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model\n",
            "2021-05-02 15:34:42.533567: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-05-02 15:34:42.563181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-05-02 15:34:42.640360: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-05-02 15:34:42.640429: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (09f938e92aef): /proc/driver/nvidia/version does not exist\n",
            "2021-05-02 15:34:42.643852: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 1.19s\n",
            "I0502 15:34:43.276511 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 1.19s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.38s\n",
            "I0502 15:34:43.652830 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.38s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0502 15:34:43.653736 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I0502 15:34:43.685687 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0502 15:34:43.708875 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0502 15:34:43.733243 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.16s\n",
            "I0502 15:34:43.889966 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.16s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.15s\n",
            "I0502 15:34:44.043454 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.15s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.16s\n",
            "I0502 15:34:44.202444 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.16s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.16s\n",
            "I0502 15:34:44.360432 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.16s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.17s\n",
            "I0502 15:34:44.529726 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.17s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
            "I0502 15:34:44.577145 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0502 15:34:44.897747 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0502 15:34:44.897992 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
            "I0502 15:34:44.898058 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
            "I0502 15:34:44.904751 140231160166272 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0502 15:34:44.965463 140231160166272 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0502 15:34:44.965699 140231160166272 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0502 15:34:45.041458 140231160166272 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0502 15:34:45.041687 140231160166272 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0502 15:34:45.204404 140231160166272 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0502 15:34:45.204629 140231160166272 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0502 15:34:45.364179 140231160166272 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0502 15:34:45.364407 140231160166272 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0502 15:34:45.621509 140231160166272 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0502 15:34:45.621742 140231160166272 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0502 15:34:46.051427 140231160166272 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0502 15:34:46.051665 140231160166272 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0502 15:34:46.398895 140231160166272 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0502 15:34:46.399140 140231160166272 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0502 15:34:46.484638 140231160166272 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0502 15:34:46.536797 140231160166272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0502 15:34:46.623491 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0502 15:34:46.623735 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
            "I0502 15:34:46.623808 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n",
            "I0502 15:34:46.629044 140231160166272 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0502 15:34:46.647462 140231160166272 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0502 15:34:46.647650 140231160166272 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0502 15:34:46.778386 140231160166272 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0502 15:34:46.778609 140231160166272 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0502 15:34:47.029600 140231160166272 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0502 15:34:47.029843 140231160166272 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0502 15:34:47.277073 140231160166272 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0502 15:34:47.277329 140231160166272 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0502 15:34:47.608824 140231160166272 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0502 15:34:47.609058 140231160166272 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0502 15:34:47.947899 140231160166272 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0502 15:34:47.948166 140231160166272 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0502 15:34:48.371184 140231160166272 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0502 15:34:48.371432 140231160166272 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0502 15:34:48.549936 140231160166272 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0502 15:34:48.590713 140231160166272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0502 15:34:48.678873 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0502 15:34:48.679117 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
            "I0502 15:34:48.679180 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n",
            "I0502 15:34:48.683981 140231160166272 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0502 15:34:48.700595 140231160166272 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0502 15:34:48.700731 140231160166272 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0502 15:34:48.830471 140231160166272 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0502 15:34:48.830729 140231160166272 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0502 15:34:49.075054 140231160166272 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0502 15:34:49.075305 140231160166272 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0502 15:34:49.549524 140231160166272 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0502 15:34:49.549790 140231160166272 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0502 15:34:49.885165 140231160166272 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0502 15:34:49.885402 140231160166272 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0502 15:34:50.226694 140231160166272 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0502 15:34:50.226924 140231160166272 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0502 15:34:50.653153 140231160166272 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0502 15:34:50.653394 140231160166272 efficientnet_model.py:147] round_filter input=320 output=352\n",
            "I0502 15:34:50.832616 140231160166272 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
            "I0502 15:34:50.870628 140231160166272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0502 15:34:50.959228 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0502 15:34:50.959455 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
            "I0502 15:34:50.959519 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n",
            "I0502 15:34:50.964384 140231160166272 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0502 15:34:50.982232 140231160166272 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0502 15:34:50.982426 140231160166272 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0502 15:34:51.113251 140231160166272 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0502 15:34:51.113502 140231160166272 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0502 15:34:51.356422 140231160166272 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0502 15:34:51.356648 140231160166272 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0502 15:34:51.599829 140231160166272 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0502 15:34:51.600065 140231160166272 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0502 15:34:52.020473 140231160166272 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0502 15:34:52.020716 140231160166272 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0502 15:34:52.439277 140231160166272 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0502 15:34:52.439500 140231160166272 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0502 15:34:52.960561 140231160166272 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0502 15:34:52.960829 140231160166272 efficientnet_model.py:147] round_filter input=320 output=384\n",
            "I0502 15:34:53.140929 140231160166272 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
            "I0502 15:34:53.179001 140231160166272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0502 15:34:53.275696 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0502 15:34:53.275938 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
            "I0502 15:34:53.276003 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0502 15:34:53.281029 140231160166272 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0502 15:34:53.299871 140231160166272 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0502 15:34:53.300083 140231160166272 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0502 15:34:53.435319 140231160166272 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0502 15:34:53.435556 140231160166272 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0502 15:34:54.065366 140231160166272 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0502 15:34:54.065611 140231160166272 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0502 15:34:54.404420 140231160166272 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0502 15:34:54.404656 140231160166272 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0502 15:34:54.913704 140231160166272 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0502 15:34:54.913934 140231160166272 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0502 15:34:55.417453 140231160166272 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0502 15:34:55.417695 140231160166272 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0502 15:34:56.121232 140231160166272 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0502 15:34:56.121520 140231160166272 efficientnet_model.py:147] round_filter input=320 output=448\n",
            "I0502 15:34:56.299549 140231160166272 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
            "I0502 15:34:56.341022 140231160166272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0502 15:34:56.449909 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0502 15:34:56.450205 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
            "I0502 15:34:56.450306 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0502 15:34:56.455293 140231160166272 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0502 15:34:56.473223 140231160166272 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0502 15:34:56.473401 140231160166272 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0502 15:34:56.668410 140231160166272 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0502 15:34:56.668653 140231160166272 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0502 15:34:57.084616 140231160166272 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0502 15:34:57.084873 140231160166272 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0502 15:34:57.500735 140231160166272 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0502 15:34:57.500971 140231160166272 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0502 15:34:58.096916 140231160166272 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0502 15:34:58.097170 140231160166272 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0502 15:34:58.988013 140231160166272 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0502 15:34:58.988305 140231160166272 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0502 15:34:59.797191 140231160166272 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0502 15:34:59.797436 140231160166272 efficientnet_model.py:147] round_filter input=320 output=512\n",
            "I0502 15:35:00.087921 140231160166272 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
            "I0502 15:35:00.130897 140231160166272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0502 15:35:00.250679 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0502 15:35:00.250921 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0502 15:35:00.250991 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0502 15:35:00.255895 140231160166272 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0502 15:35:00.273917 140231160166272 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0502 15:35:00.274131 140231160166272 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0502 15:35:00.477098 140231160166272 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0502 15:35:00.477381 140231160166272 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0502 15:35:00.981539 140231160166272 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0502 15:35:00.981822 140231160166272 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0502 15:35:01.491731 140231160166272 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0502 15:35:01.492015 140231160166272 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0502 15:35:02.199115 140231160166272 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0502 15:35:02.199385 140231160166272 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0502 15:35:02.883372 140231160166272 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0502 15:35:02.883630 140231160166272 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0502 15:35:04.215776 140231160166272 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0502 15:35:04.216014 140231160166272 efficientnet_model.py:147] round_filter input=320 output=576\n",
            "I0502 15:35:04.508482 140231160166272 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
            "I0502 15:35:04.552238 140231160166272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0502 15:35:04.685459 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0502 15:35:04.685695 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0502 15:35:04.685780 140231160166272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0502 15:35:04.690577 140231160166272 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0502 15:35:04.708016 140231160166272 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0502 15:35:04.708208 140231160166272 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0502 15:35:04.966809 140231160166272 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0502 15:35:04.967055 140231160166272 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0502 15:35:05.554404 140231160166272 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0502 15:35:05.554662 140231160166272 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0502 15:35:06.150271 140231160166272 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0502 15:35:06.150516 140231160166272 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0502 15:35:07.026199 140231160166272 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0502 15:35:07.026519 140231160166272 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0502 15:35:07.901530 140231160166272 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0502 15:35:07.901765 140231160166272 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0502 15:35:09.124005 140231160166272 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0502 15:35:09.124293 140231160166272 efficientnet_model.py:147] round_filter input=320 output=640\n",
            "I0502 15:35:09.544697 140231160166272 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
            "I0502 15:35:09.971103 140231160166272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 25.54s\n",
            "I0502 15:35:10.122732 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 25.54s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0502 15:35:10.132644 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0502 15:35:10.134638 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0502 15:35:10.135142 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0502 15:35:10.136738 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0502 15:35:10.138193 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0502 15:35:10.138624 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0502 15:35:10.139618 140231160166272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 21 tests in 28.052s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGKtsoeIA8Gc"
      },
      "source": [
        "%cd /content/drive/MyDrive/semester_2_final_project/tf_model/models/research\n",
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMWSzZKhwe6b"
      },
      "source": [
        "\n",
        "from object_detection.utils import dataset_util\n",
        "from object_detection.utils import label_map_util"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhEeXV5Pmn7e"
      },
      "source": [
        "\n",
        "\n",
        "from object_detection.utils import dataset_util\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "\n",
        "SETS = ['train', 'test', 'merged']\n",
        "def dict_to_tf_example(annotation, dataset_directory, label_map_dict):\n",
        "  im_path = str(annotation['fname'])\n",
        "  cls = int(annotation['class'])\n",
        "  x1 = int(annotation['bbox_x1'])\n",
        "  y1 = int(annotation['bbox_y1'])\n",
        "  x2 = int(annotation['bbox_x2'])\n",
        "  y2 = int(annotation['bbox_y2'])\n",
        "\n",
        "  # read image\n",
        "  full_img_path = os.path.join(dataset_directory, im_path)\n",
        "\n",
        "  # read in the image and make a thumbnail of it\n",
        "  max_size = 300, 300\n",
        "  big_image = PIL.Image.open(full_img_path)\n",
        "  width,height = big_image.size\n",
        "  big_image.thumbnail(max_size, PIL.Image.ANTIALIAS)\n",
        "  full_thumbnail_path = os.path.splitext(full_img_path)[0] + '_thumbnail.jpg'\n",
        "  big_image.save(full_thumbnail_path)\n",
        "\n",
        "  with tf.io.gfile.GFile(full_thumbnail_path, 'rb') as fid:\n",
        "    encoded_jpg = fid.read()\n",
        "  encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "  image = PIL.Image.open(encoded_jpg_io)\n",
        "\n",
        "  xmin = []\n",
        "  xmax = []\n",
        "  ymin = []\n",
        "  ymax = []\n",
        "\n",
        "  # calculate box using original image coordinates\n",
        "  xmin.append(max(0, x1 / width))\n",
        "  xmax.append(min(1.0, x2 / width))\n",
        "  ymin.append(max(0, y1 / height))\n",
        "  ymax.append(min(1.0, y2 / height))\n",
        "\n",
        "  # set width and height to thumbnail size for tfrecord ingest\n",
        "  width,height = image.size\n",
        "\n",
        "  classes = []\n",
        "  classes_text = []\n",
        "\n",
        "  label=''\n",
        "  for name, val in label_map_dict.items():\n",
        "    if val == cls: \n",
        "      label = name\n",
        "      break\n",
        "\n",
        "  classes_text.append(label.encode('utf8'))\n",
        "  classes.append(label_map_dict[label])\n",
        "  \n",
        "  example = tf.train.Example(features=tf.train.Features(feature={\n",
        "\t'image/height': dataset_util.int64_feature(height),\n",
        "\t'image/width': dataset_util.int64_feature(width),\n",
        "\t'image/filename': dataset_util.bytes_feature(full_img_path.encode('utf8')),\n",
        "\t'image/source_id': dataset_util.bytes_feature(full_img_path.encode('utf8')),\n",
        "\t'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "\t'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
        "\t'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),\n",
        "\t'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),\n",
        "\t'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),\n",
        "\t'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),\n",
        "\t'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "\t'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "  }))\n",
        "  return example \n",
        "\n",
        "data_dir = '/content/drive/MyDrive/semester_2_final_project/data/training_set/cars_train'\n",
        "csv_file = '/content/drive/MyDrive/semester_2_final_project/data/annotations/train.csv'\n",
        "\n",
        "writer =  tf.compat.v1.python_io.TFRecordWriter('/content/drive/MyDrive/semester_2_final_project/data/annotations/stanford_cars.tfrecord')\n",
        "label_map_dict = label_map_util.get_label_map_dict('/content/drive/MyDrive/semester_2_final_project/data/annotations/train_label_map_10.pbtxt')\n",
        "count=0;\n",
        "with open(csv_file) as f:\n",
        "  csv_reader = csv.DictReader(f)\n",
        "  for row in csv_reader:\n",
        "    tf_example = dict_to_tf_example(row, data_dir, label_map_dict)\n",
        "    writer.write(tf_example.SerializeToString())\n",
        "    count+=1;\n",
        "    print(count)\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9cs9_dxGQ8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a56a77f-4ae5-4776-d795-bc4f8091c701"
      },
      "source": [
        "%cd /content/drive/MyDrive/semester_2_final_project/data/annotations\n",
        "%cp stanford_cars.tfrecord  stanford_cars_test.tfrecord\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/semester_2_final_project/data/annotations\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqxAQ3Tx4WEs"
      },
      "source": [
        "import tensorflow as tf \n",
        "raw_dataset = tf.data.TFRecordDataset(\"/content/drive/MyDrive/semester_2_final_project/data/annotations/stanford_cars.tfrecord\")\n",
        "\n",
        "count=0;\n",
        "for raw_record in raw_dataset:\n",
        "    # example = tf.train.Example()\n",
        "    # example.ParseFromString(raw_record.numpy())\n",
        "    count+=1;\n",
        "    print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aTy7PF-dl8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc3f1dac-d9bb-413e-b0af-102165a146db"
      },
      "source": [
        "%cd /content/drive/MyDrive/semester_2_final_project/temp\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL ='ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/'\n",
        "#http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "\n",
        "#http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\n",
        "#http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
        "#https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
        "\n",
        "\n",
        "DEST_DIR = '/content/drive/MyDrive/semester_2_final_project/temp'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "!tar xvzf {MODEL_FILE}"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/semester_2_final_project/temp\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBbYBp9rQoR1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c312a7a-7a9e-4c66-8757-0edf64cbbe53"
      },
      "source": [
        "!pip install lvis\n",
        "!pip install tensorflow-addons\n",
        "!pip install tf-nightly"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lvis in /usr/local/lib/python3.7/dist-packages (0.5.3)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.3.1)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.4.7)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.29.22)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.19.5)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.8.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis) (4.1.2.30)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.12.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/96/93a75ce976ef08a083726f4f897a2875e9502738aeebeaf16d4b5c88ebc3/tf_nightly-2.6.0.dev20210502-cp37-cp37m-manylinux2010_x86_64.whl (456.8MB)\n",
            "\u001b[K     |████████████████████████████████| 456.8MB 22kB/s \n",
            "\u001b[?25hCollecting grpcio<2.0,>=1.37.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/d8/1bfe90cc49c166dd2ec1be46fa4830c254ce702004a110830c74ec1df0c0/grpcio-1.37.1-cp37-cp37m-manylinux2014_x86_64.whl (4.2MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2MB 53.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.7.4.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.19.5)\n",
            "Collecting tb-nightly~=2.6.0.a\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/52/fc8c251213dc6125c6c3127f9b71565fc804f7e7b3aec2e672c754291468/tb_nightly-2.6.0a20210501-py3-none-any.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 53.2MB/s \n",
            "\u001b[?25hCollecting gast==0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.12.4)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.2.0)\n",
            "Collecting h5py~=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/74/9eae2bedd8201ab464308f42c601a12d79727a1c87f0c867fdefb212c6cf/h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 50.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.2)\n",
            "Collecting tf-estimator-nightly~=2.5.0.dev\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/6c/9bf4a6004d18c8e543845d3416e50f36dd09d272161e2fb0db5678132dfd/tf_estimator_nightly-2.5.0.dev2021032601-py2.py3-none-any.whl (462kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 55.0MB/s \n",
            "\u001b[?25hCollecting keras-nightly~=2.6.0.dev\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/30/ee397771b2365e38ddfcba1b213afea36f970d4291f6840278a2d0bbfa18/keras_nightly-2.6.0.dev2021050200-py2.py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 53.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (1.28.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (0.4.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (56.0.0)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/63/d92b4bc44261b7396558c054f78acf71468b5628bcb14cdaeb2504ea80d3/tensorboard_data_server-0.6.0-py3-none-manylinux2010_x86_64.whl (3.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 47.8MB/s \n",
            "\u001b[?25hCollecting cached-property; python_version < \"3.8\"\n",
            "  Downloading https://files.pythonhosted.org/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly~=2.6.0.a->tf-nightly) (3.10.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly) (2020.12.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly) (4.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.6.0.a->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly~=2.6.0.a->tf-nightly) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.6.0.a->tf-nightly) (3.1.0)\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement grpcio~=1.32.0, but you'll have grpcio 1.37.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement h5py~=2.10.0, but you'll have h5py 3.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: grpcio, tensorboard-data-server, tb-nightly, gast, cached-property, h5py, tf-estimator-nightly, keras-nightly, tf-nightly\n",
            "  Found existing installation: grpcio 1.32.0\n",
            "    Uninstalling grpcio-1.32.0:\n",
            "      Successfully uninstalled grpcio-1.32.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "Successfully installed cached-property-1.5.2 gast-0.4.0 grpcio-1.37.1 h5py-3.1.0 keras-nightly-2.6.0.dev2021050200 tb-nightly-2.6.0a20210501 tensorboard-data-server-0.6.0 tf-estimator-nightly-2.5.0.dev2021032601 tf-nightly-2.6.0.dev20210502\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "h5py",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol_Pf0tBP2bP"
      },
      "source": [
        "\n",
        "# --checkpoint_dir=/content/drive/MyDrive/semester_2_final_project/temp/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint \\\n",
        "!python /content/drive/MyDrive/semester_2_final_project/tf_model/models/research/object_detection/model_main_tf2.py \\\n",
        "--pipeline_config_path=/content/drive/MyDrive/semester_2_final_project/temp/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config \\\n",
        "--model_dir=/content/drive/MyDrive/semester_2_final_project/temp/model_export_ssd_mobilenet_v2_fpnlite_320_GOD \\\n",
        "--num_train_steps=3000\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4I98LopYYYj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df2c020c-c43d-40e5-cdea-0b974d08b59a"
      },
      "source": [
        "PIPELINE_CONFIG_PATH='/content/drive/MyDrive/semester_2_final_project/temp/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config '\n",
        "MODEL_DIR='/content/drive/MyDrive/semester_2_final_project/temp/fine_tune_model'\n",
        "!ls {MODEL_DIR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t    ckpt-2.data-00000-of-00001\tckpt-3.index\n",
            "ckpt-1.data-00000-of-00001  ckpt-2.index\t\ttrain\n",
            "ckpt-1.index\t\t    ckpt-3.data-00000-of-00001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16TgM1YkUNt4",
        "outputId": "eea0b42c-2234-4999-e1c0-2c19f60dc4ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "!python /content/drive/MyDrive/semester_2_final_project/tf_model/models/research/object_detection/model_main_tf2.py \\ \n",
        "--model_dir=/content/drive/MyDrive/semester_2_final_project/temp/model_export_ssd_mobilenet_v2_fpnlite_320_GOD \\\n",
        "--pipeline_config_path=/content/drive/MyDrive/semester_2_final_project/temp/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config \\\n",
        "--checkpoint_dir=/content/drive/MyDrive/semester_2_final_project/temp/model_export_ssd_mobilenet_v2_fpnlite_320_GOD/"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-a3961a4e862e>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    --model_dir=/content/drive/MyDrive/semester_2_final_project/temp/model_export_ssd_mobilenet_v2_fpnlite_320_GOD --pipeline_config_path=/content/drive/MyDrive/semester_2_final_project/temp/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config --checkpoint_dir=/content/drive/MyDrive/semester_2_final_project/temp/model_export_ssd_mobilenet_v2_fpnlite_320_GOD/\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShaPszYOxx5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "2f1b9615-17fc-405d-d7c6-b3008f584a53"
      },
      "source": [
        "\n",
        "!python /content/drive/MyDrive/semester_2_final_project/tf_model/models/research/object_detection/exporter_main_v2.py  \\ \n",
        "--input_type=image_tensor \\ \n",
        "--pipeline_config_path /content/drive/MyDrive/semester_2_final_project/temp/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config \\\n",
        "--trained_checkpoint_dir  '/content/drive/MyDrive/semester_2_final_project/temp/model_export_ssd_mobilenet_v2_fpnlite_320_GOD' \\\n",
        "--output_directory /content/drive/MyDrive/semester_2_final_project/model_export2/model_export_ssd_mobilenet_v2_fpnlite_320_GOD"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-635e25aace63>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    --input_type=image_tensor \\\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsAyFVUsZALV"
      },
      "source": [
        "# !python /content/drive/MyDrive/semester_2_final_project/tf_model/models/research/object_detection/exporter_main_v2.py \\\n",
        "#  --input_type image_tensor \\\n",
        "#  --pipeline_config_path {PIPELINE_CONFIG_PATH} \\\n",
        "#  --trained_checkpoint_dir  '/content/drive/MyDrive/semester_2_final_project/temp/fine_tune_model' \\\n",
        "#  --output_directory /content/drive/MyDrive/semester_2_final_project/model_export1_image_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2O8hL1YnVdy"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GStNeHWPkTcN"
      },
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: the file path to the image\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# detect_fn =tf.saved_model.load('/content/drive/MyDrive/semester_2_final_project/model_export/saved_model')\n",
        "detect_fn =tf.saved_model.load('/content/drive/MyDrive/semester_2_final_project/model_export2/ssd_mobile_fpn_640_god/saved_model')\n",
        "category_index = label_map_util.create_category_index_from_labelmap('/content/drive/MyDrive/semester_2_final_project/data/annotations/train_label_map_10.pbtxt',\n",
        "                                                                    use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFyow0ucVDm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dfb4368-9a16-4d41-cbc9-3f6280f3936b"
      },
      "source": [
        "detect_fn.graph_debug_info"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-YpX_IVT-QJ"
      },
      "source": [
        "for image_path in ['/content/drive/MyDrive/semester_2_final_project/data/test_set/cars_test/eval/00002.jpg']:\n",
        "\n",
        "    print('Running inference for {}... '.format(image_path), end='')\n",
        "\n",
        "    # image_np = load_image_into_numpy_array(image_path)\n",
        "     \n",
        "    image_np = np.asarray(Image.open(image_path)).astype('uint8')\n",
        "\n",
        "    # Things to try:\n",
        "    # Flip horizontally\n",
        "    # image_np = np.fliplr(image_np).copy()\n",
        "\n",
        "    # Convert image to grayscale\n",
        "    # image_np = np.tile(\n",
        "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "    input_tensor = tf.convert_to_tensor(image_np)\n",
        "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    # input_tensor = np.expand_dims(image_np, 0)\n",
        "    print(input_tensor)\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    # All outputs are batches tensors.\n",
        "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "    # We're only interested in the first num_detections.\n",
        "    num_detections = detections.pop('num_detections')\n",
        "    print(num_detections)\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "    print(num_detections)\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np_with_detections,\n",
        "          detections['detection_boxes'],\n",
        "          detections['detection_classes'],\n",
        "          detections['detection_scores'],\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          max_boxes_to_draw=200,\n",
        "          min_score_thresh=.30,\n",
        "          agnostic_mode=False)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(image_np_with_detections)\n",
        "    print('Done')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezfBs-cpkUoX"
      },
      "source": [
        "configs = config_util.get_configs_from_pipeline_file('/content/drive/MyDrive/semester_2_final_project/model_export2/ssd_mobile_fpn_640_god/pipeline.config')\n",
        "model_config = configs['model']\n",
        "\n",
        "detection_model = model_builder.build(\n",
        "      model_config=model_config, is_training=False)\n",
        "ckpt = tf.compat.v2.train.Checkpoint(\n",
        "      model=detection_model)\n",
        "ckpt.restore(os.path.join('/content/drive/MyDrive/semester_2_final_project/model_export/checkpoint', 'ckpt-0')).expect_partial()\n",
        "\n",
        "def get_model_detection_function(model):\n",
        "  \"\"\"Get a tf.function for detection.\"\"\"\n",
        "\n",
        "  @tf.function\n",
        "  def detect_fn(image):\n",
        "    \"\"\"Detect objects in image.\"\"\"\n",
        "\n",
        "    image, shapes = model.preprocess(image)\n",
        "    prediction_dict = model.predict(image, shapes)\n",
        "    detections = model.postprocess(prediction_dict, shapes)\n",
        "\n",
        "    return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
        "\n",
        "  return detect_fn\n",
        "\n",
        "detect_fn = get_model_detection_function(detection_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIdrjFeIYM_e"
      },
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap('/content/drive/MyDrive/semester_2_final_project/data/annotations/train_label_map_10.pbtxt',\n",
        "                                                                    use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2Nj0jPkYT9U"
      },
      "source": [
        "!python /content/drive/MyDrive/semester_2_final_project/tf_model/models/research/object_detection/packages/tf2/setup.py install\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srBaKLEqYni-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8877e05e-cb59-4cac-f331-397d4b350894"
      },
      "source": [
        "\n",
        "for image_path in ['/content/drive/MyDrive/semester_2_final_project/data/training_set/cars_train/00002_thumbnail.jpg']:\n",
        "\n",
        "    print('Running inference for {}... '.format(image_path), end='')\n",
        "\n",
        "    image_np = np.asarray(Image.open(image_path)).astype('uint8')\n",
        "\n",
        "    # Things to try:\n",
        "    # Flip horizontally\n",
        "    # image_np = np.fliplr(image_np).copy()\n",
        "\n",
        "    # Convert image to grayscale\n",
        "    # image_np = np.tile(\n",
        "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "    # input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    # input_tensor = np.expand_dims(image_np, 0)\n",
        "    print('prediction')\n",
        "    print(input_tensor)\n",
        "    tf.config.experimental_run_functions_eagerly(False)\n",
        "    # image1, shapes = detection_model.preprocess(input_tensor)\n",
        "    # prediction_dict = detection_model.predict(image1, shapes)\n",
        "    # detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
        "    print(detections)\n",
        "    print(tf.squeeze(detections['detection_boxes'], [0]))\n",
        "    print(np.array(detections['detection_boxes'], [0]))\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np_with_detections,\n",
        "          detections['detection_boxes'],\n",
        "          detections['detection_classes'],\n",
        "          detections['detection_scores'],\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          max_boxes_to_draw=200,\n",
        "          min_score_thresh=.30,\n",
        "          agnostic_mode=False)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(image_np_with_detections)\n",
        "    print('Done')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running inference for /content/drive/MyDrive/semester_2_final_project/data/training_set/cars_train/00002_thumbnail.jpg... prediction\n",
            "tf.Tensor(\n",
            "[[[[172. 173. 178.]\n",
            "   [175. 176. 181.]\n",
            "   [179. 180. 185.]\n",
            "   ...\n",
            "   [255. 255. 255.]\n",
            "   [255. 255. 255.]\n",
            "   [255. 255. 255.]]\n",
            "\n",
            "  [[171. 172. 177.]\n",
            "   [174. 175. 180.]\n",
            "   [178. 179. 184.]\n",
            "   ...\n",
            "   [255. 255. 255.]\n",
            "   [255. 255. 255.]\n",
            "   [255. 255. 255.]]\n",
            "\n",
            "  [[179. 180. 185.]\n",
            "   [181. 182. 187.]\n",
            "   [185. 186. 191.]\n",
            "   ...\n",
            "   [255. 255. 255.]\n",
            "   [255. 255. 255.]\n",
            "   [255. 255. 255.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[143. 134. 125.]\n",
            "   [147. 138. 129.]\n",
            "   [151. 142. 133.]\n",
            "   ...\n",
            "   [146. 141. 137.]\n",
            "   [143. 138. 134.]\n",
            "   [146. 141. 137.]]\n",
            "\n",
            "  [[140. 131. 122.]\n",
            "   [143. 134. 125.]\n",
            "   [148. 139. 130.]\n",
            "   ...\n",
            "   [149. 144. 140.]\n",
            "   [149. 144. 140.]\n",
            "   [156. 151. 147.]]\n",
            "\n",
            "  [[148. 140. 129.]\n",
            "   [141. 133. 122.]\n",
            "   [154. 146. 135.]\n",
            "   ...\n",
            "   [149. 144. 140.]\n",
            "   [144. 139. 135.]\n",
            "   [140. 135. 131.]]]], shape=(1, 225, 300, 3), dtype=float32)\n",
            "WARNING:tensorflow:From <ipython-input-15-94fa117d94ac>:24: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.run_functions_eagerly` instead of the experimental version.\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f016c216c10> and <tensorflow.python.keras.layers.core.Lambda object at 0x7f016aa47350>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f015655b490> and <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f016c216c10>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f01686ca550> and <tensorflow.python.keras.layers.core.Lambda object at 0x7f016c089950>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f016b990c50> and <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f01686ca550>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f01690a3bd0> and <tensorflow.python.keras.layers.core.Lambda object at 0x7f015651a810>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f016af7b910> and <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f01690a3bd0>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0169097390> and <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f016af7b910>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f01690a34d0> and <tensorflow.python.keras.layers.core.Lambda object at 0x7f01565ced10>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f0156527d10> and <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f01690a34d0>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0169160110> and <tensorflow.python.keras.layers.core.Lambda object at 0x7f016b14d510>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0168d35190> and <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0169160110>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f016c110d50> and <tensorflow.python.keras.layers.core.Lambda object at 0x7f0168ccd3d0>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f0168f81650> and <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f016c110d50>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0168ccd410> and <tensorflow.python.keras.layers.core.Lambda object at 0x7f015653bb10>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f016ba38090> and <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0168ccd410>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f015651df90> and <tensorflow.python.keras.layers.core.Lambda object at 0x7f016abef2d0>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f016889b450> and <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f015651df90>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f016871f6d0> and <tensorflow.python.keras.layers.core.Lambda object at 0x7f0169ece450>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0169156410> and <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f016889b450>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0156541ad0> and <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f016871f6d0>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f01564b2450> and <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0169156410>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0168f13850> and <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0156541ad0>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f016912ded0> and <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f01564b2450>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f01564b2b10> and <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0168f13850>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f0168cd4290> and <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f016912ded0>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0156589810> and <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f01564b2b10>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0168fce090> and <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f0168cd4290>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0168fd9990> and <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0156589810>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f0168e01750> and <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0168fce090>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0168df3390> and <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0168fd9990>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f01564e6910> and <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f0168e01750>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0168e011d0> and <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0168df3390>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f0168ce44d0> and <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f01564e6910>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0168f67a10> and <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0168e011d0>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0168d103d0> and <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f0168ce44d0>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0168ce4190> and <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0168f67a10>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f0168e015d0> and <tensorflow.python.keras.layers.core.Lambda object at 0x7f0168d15650>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0168f50550> and <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0168d103d0>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f016bdbd890> and <tensorflow.python.keras.layers.core.Lambda object at 0x7f016ab652d0>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0168bcdbd0> and <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f0168e015d0>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f0156503910> and <tensorflow.python.keras.layers.core.Lambda object at 0x7f016abbae90>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f015654ee50> and <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f016bdbd890>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f016a9ed7d0> and <tensorflow.python.keras.layers.core.Lambda object at 0x7f015654e3d0>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f0156545050> and <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f0156503910>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f01690e6590> and <tensorflow.python.keras.layers.core.Lambda object at 0x7f016912d110>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f015658ced0> and <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f016a9ed7d0>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f015650e850> and <tensorflow.python.keras.layers.core.Lambda object at 0x7f0168f13950>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f016908d890> and <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f01690e6590>).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-94fa117d94ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# prediction_dict = detection_model.predict(image1, shapes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# detections = detection_model.postprocess(prediction_dict, shapes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'detection_boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-13-cbf7581883dd>:18 detect_fn  *\n        prediction_dict = model.predict(image, shapes)\n    /content/drive/My Drive/semester_2_final_project/tf_model/models/research/object_detection/meta_architectures/ssd_meta_arch.py:570 predict  *\n        feature_maps = self._feature_extractor(preprocessed_inputs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1008 __call__  **\n        self._maybe_build(inputs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2710 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    /content/drive/My Drive/semester_2_final_project/tf_model/models/research/object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py:153 build\n        conv2d_11_pointwise, conv2d_13_pointwise]\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:324 __setattr__\n        super(Model, self).__setattr__(name, value)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2839 __setattr__\n        trackable=self, value=value, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/data_structures.py:136 sticky_attribute_assignment\n        overwrite=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py:909 _track_trackable\n        self._handle_deferred_dependencies(name=name, trackable=trackable)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py:942 _handle_deferred_dependencies\n        checkpoint_position.restore(trackable)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py:253 restore\n        restore_ops = trackable._restore_from_checkpoint_position(self)  # pylint: disable=protected-access\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py:973 _restore_from_checkpoint_position\n        tensor_saveables, python_saveables))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py:308 restore_saveables\n        validated_saveables).restore(self.save_path_tensor, self.options)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saving/functional_saver.py:345 restore\n        restore_ops = restore_fn()\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saving/functional_saver.py:321 restore_fn\n        restore_ops.update(saver.restore(file_prefix, options))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saving/functional_saver.py:116 restore\n        restored_tensors, restored_shapes=None)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saving/saveable_object_util.py:132 restore\n        self.handle_op, self._var_shape, restored_tensor)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:307 shape_safe_assign_variable_handle\n        shape.assert_is_compatible_with(value_tensor.shape)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (128,) and (24,) are incompatible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cBmOV0z_hNV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "82868da8-2139-43aa-d073-54d0c297b232"
      },
      "source": [
        "\n",
        "\n",
        "print(np.array(detections['detection_boxes']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-150-741315bc9a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'detection_boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0;34m\"Cannot convert a symbolic Tensor ({}) to a numpy array.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;34m\" This error may indicate that you're trying to pass a Tensor to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m         \" a NumPy call, which is not supported\".format(self.name))\n\u001b[0m\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (Postprocessor_13/BatchMultiClassNonMaxSuppression/stack_6:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z3ZRiBNBhfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "711bc770-c223-41ae-df08-30b9dbd6b9bc"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-148-9063a9f0e032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ]
    }
  ]
}